I% Chapter Template
%\pagenumbering{gobble}
\lhead{} 

\chapter{Introduction} % Main chapter title
%\pagenumbering{arabic}
\label{Introduction} % Change X to a consecutive number; for referencing this chapter elsewhere, use \ref{ChapterX}

\lhead{\emph{Introduction}} % Change X to a consecutive number; this is for the header on each page - perhaps a shortened title

%----------------------------------------------------------------------------------------
%	SECTION 1
%----------------------------------------------------------------------------------------

\section{Motivation}
With the increase in multicore machines, programs tend to use more parallelism and concurrency. In these contexts, managing mutable data structures introduces more complexity. Thread safety can become a burden on the programmer and the machine. A simpler approach is using immutable data structures, where elements can be accessed directly without any risk of corruption due to race conditions. 
%In classical functional programming immutable data structures are a requirement. In languages like Scala where there is a functional side and an object oriented side immutable data is not longer required, but the compiler provides better optimizations on them.


% what are vectors
%% highly optimized
%% lack of efficient concatenation
%%% parallel vector is suboptimal
Scala has a rich collection of immutable data structures as well as parallel versions that divide their work transparently on thread pools. Where the vector is used as the default general purpose parallel sequence. The immutable vector is based on balanced wide trees, called RB-Trees, to allow effective constant time in practice on its key operations: get element at index, update element at index, append, prepend and splitting the vector. But, one of the operations required for parallelism, the concatenation operation is suboptimal.

% what are rrb tree (RRBTrees paper \cite{RRBTrees})
%% efficient concatenation
%% lacks the other operations
To improve parallel performance, P. Bagwell and T. Rompf proposed a relaxed structure for the vector \cite{RRBTrees}. The Relaxed Radix Balanced Tree allows the tree to be partially filled, in turn allowing amortized constant-time concatenation. The drawback is in the loss of some optimizations opportunities due to the relaxation, which leads to the loss of amortized constant-time sequential operations due to the relaxation.


\section{Objective}
% use rrb-trees for vectors (This project repository \cite{projecRepo})
%% generalize operations
%% without loosing performance other operations
%% keep the optimisations whenever possible
%% implementation aims to be production ready (not prototype)
The main objective of this project was to implement\footnote{Implementation is located a \url{https://github.com/nicolasstucki/scala-rrb-vector} \cite{projecRepo}} version of the Scala immutable Vector using RRB-Trees that could potentially replace the old one. As such the new implementation is functionally equivalent to the old one.

To provide the same performance and amortized constant-time operations of RB-Tree, we base the implementation on a composition of generic RRB-Tree operations with more performant RB-Tree operations. Using the most efficient operations on any tree or subtree where the stricter structure invariant holds. When possible, generalizations of optimizations are devised in the RRB operations and in other cases new optimizations opportunities are exploited. To enhance these benefits, the tree transformations favour the creation of RB-Trees or subtrees.

% The challenges behind this implementation where to have an implementation that would be as performant as the old one for all operations excepting the concatenation, even when the relaxed representation of the tree can't take advantage of some key optimization. To avoid the complete loss of optimization, ways to apply such optimizations partially where explored and applied.

\section{Results}
% benchmark and analysis the performance
%% compare with the current vector
%% compare with other implementation variants
To show and analyze the trade-offs between the implementations extensive benchmarks where realized on all core operations of the vectors. These compare the current vector with an array of different RRB-Trees including: different tree branching sizes, different implementation of concatenation algorithm and differently unbalanced RRB-Trees.  

The implementation successfully integrated the the RRB-Trees with the radix based optimizations. As such the new Vector implementation has constant time for all operation on which it had before and on the additional concatenation and insertion operations. Form this it was possible to create a parallel vector that takes full advantage of the fork-join pool parallelization. Benchmarks showed a 2.3X improvement on the data split and combination on a pool with 4 threads.

The benchmarks showed that for almost all pre-existing constant time operations the performance achieved was almost identical. The few cases that do not have the same performance are still well bounded by constant time. It was shown that even with an apparently less compact tree structure the change in memory footprint negligible.

\section{Document Structure}
% section 2:
%% 1. introduce the vector and structure of the current vector and the operations in a generic
%% 2. related structures that uses the trees
%% 3. how the tree structure is relaxed and how it affects the operarations
%%% addition of concatenation and insert at
In chapter \ref{VectorStructure} we discuss the data structures and operations: Section \ref{RadixBalancedVectors} describes the current version of the vector structure and operations, section \ref{RelatedStructures} discusses related data structure that use the same trees in other ways (like the iterator of a vector), section \ref{RelaxedRadixBalancedVectors} describes the RRB-Tree and how to relax the operations based on the non relaxed versions.

% section 3: optimizations done on the implementations
%% 1. discussion on representations of data and code. how this affects performance
%% 2. discussion of optimization that aim to amortize the operations to constant time.
%% 3. related structures optimized implementations
In chapter \ref{Optimizations} we describe the optimization done on the current version of the vector and how they are affected by the relaxation. In section \ref{WhereIsTimeSpent} we describe where most of the processing time is spent and how it optimizations use this information. In section \ref{sec:Displays} we describe the optimizations that are used to reduce the algorithmic complexities of some operations. In section \ref{OptimizationRelatedStructures} we describe the implementation of the related structures and optimizations on them.

% section 4: performance in practice
%% 1. Discussion on JVM performance caracteristics and how it was used in the implementation
%% 2-3 How the was performance measured
%% 4 benchmarks results
In chapter \ref{Performance} we discuss the performance of the implementation in practice. In section \ref{InPractice} we describe characteristics of the JVM and how to take advantage of them. In sections \ref{Measuringperformance} and \ref{ImplementationGenerators} we describe the benchmarks used to measure performance. In section \ref{Benchmarks} we show  the results of the benchmarks and analyze it.


% section 5: testing the correctness of the code
% section 6: related work and future work
% section 7: conclude in section 7
In chapter \ref{Testing} we present the testing methodology and in section \ref{RelatedWork} we review the related work. We conclude in in section \ref{Conclusions}.




