I% Chapter Template
%\pagenumbering{gobble}
\lhead{} 

\chapter{Introduction} % Main chapter title
%\pagenumbering{arabic}
\label{Introduction} % Change X to a consecutive number; for referencing this chapter elsewhere, use \ref{ChapterX}

\lhead{\emph{Introduction}} % Change X to a consecutive number; this is for the header on each page - perhaps a shortened title

%----------------------------------------------------------------------------------------
%	SECTION 1
%----------------------------------------------------------------------------------------

\section{Motivation}
With the increase on multicore machines, programs tend to use more parallelism and concurrency. In these contexts, managing mutable data structures introduces more complexity. The managements of the thread safeness can become a burden on the programmer and the machine. A simpler approach is using immutable data structures, where elements can be accessed directly without any risk of corruption due to race conditions. In classical functional programming immutable data structures are a requirement. In languages like Scala where there is a functional side and an object oriented side immutable data is not longer required, but the compiler provides better optimizations on them.

% what are vectors
%% highly optimized
%% lack of efficient concatenation
%%% parallel vector is suboptimal
Scala has a rich collection of immutable data structures as well as parallel versions that divide their work transparently on thread pools. Where the \texttt{Vector} is used as the default general purpose parallel sequence. The immutable vector is designed to have effective constant time in practice on its key operations: get element at index, update element at index, insert on an end of the vector and splitting the vector. But, one of the operations required for parallelism is an efficient concatenation.

% what are rrb tree (RRBTrees paper \cite{RRBTrees})
%% efficient concatenation
%% lacks the other operations
To improve this operation P. Bagwell and T. Rompf proposed a less strict structure for the vector \cite{RRBTrees}. They propose the use of a Relaxed Radix Balanced Tree instead of the current Radix Balanced Tree. With these trees it is additionally possible to implement effective constant time concatenation and inserts in any position. The drawback is in the loss of some optimizations opportunities due to the relaxation.

\section{Objective}
% use rrb-trees for vectors (This project repository \cite{projecRepo})
%% generalize operations
%% without loosing performance other operations
%% keep the optimisations whenever possible
%% implementation aims to be production ready (not prototype)
The main objective of this project was to implement\footnote{Implementation is located a \url{https://github.com/nicolasstucki/scala-rrb-vector} \cite{projecRepo}} version of the Scala immutable Vector using RRB-Trees that could potentially replace the old one. The challenges behind this implementation where to have an implementation that would be as performant as the old one for all operations excepting the concatenation, even when the relaxed representation of the tree can't take advantage of some key optimization. To avoid the complete loss of optimization, ways to apply such optimizations partially where explored and applied.

% benchmark and analysis the performance
%% compare with the current vector
%% compare with other implementation variants
To show and analyze the tradeoffs between the implementations extensive benchmarks where realized on all core operations of the vectors. These compare the current vector with an array of different RRB-Trees including: different tree branching sizes, different implementation of concatenation algorithm and differently unbalanced RRB-Trees.  

\section{Results}

The implementation successfully integrated the the RRB-Trees with the radix based optimizations. As such the new Vector implementation has constant time for all operation on which it had before and on the additional concatenation and insertion operations. Form this it was possible to create a parallel vector that takes full advantage of the fork-join pool paralellization. Benchmarks showed a 2.3X improvement on the data split and combination on a pool with 4 threads.

The benchmarks showed that for almost all preexisting constant time operations the performance achieved was almost identical. The few cases that do not have the same performance are still well bounded by constant time. It was shown that even with an apparently less compact tree structure the change in memory footprint negligible.

\section{Document Structure}
% section 2:
%% 1. introduce the vector and structure of the current vector and the operations in a generic
%% 2. related structures that uses the trees
%% 3. how the tree structure is relaxed and how it affects the operarations
%%% addition of concatenation and insert at
In chapter \ref{VectorStructure} we discuss the data structures and operations: Section \ref{RadixBalancedVectors} describes the current version of the vector structure and operations, section \ref{RelatedStructures} discusses related data structure that use the same trees in other ways (like the iterator of a vector), section \ref{RelaxedRadixBalancedVectors} describes the RRB-Tree and how to relax the operations based on the non relaxed versions.

% section 3: optimizations done on the implementations
%% 1. discussion on representations of data and code. how this affects performance
%% 2. discussion of optimization that aim to amortize the operations to constant time.
%% 3. related structures optimized implementations
In chapter \ref{Optimizations} we describe the optimization done on the current version of the vector and how they are affected by the relaxation. In section \ref{WhereIsTimeSpent} we discuss optimizations on the representation of data and the code. In section \ref{sec:Displays} we describe the optimizations that are used to reduce the algorithmic complexities of some operations. In section \ref{OptimizationRelatedStructures} we describe the implementation of the related structures and optimizations on them.

% section 4: performance in practice
%% 1. Discussion on JVM performance caracteristics and how it was used in the implementation
%% 2-3 How the was performance measured
%% 4 benchmarks results
In chapter \ref{Performance} we discuss the performance of the implementation in practice. In section \ref{InPractice} we describe characteristics of the JVM and how to take advantage of them. In sections \ref{Measuringperformance} and \ref{ImplementationGenerators} we describe the benchmarks used to measure performance. In section \ref{Benchmarks} we show  the results of the benchmarks and analyze it.

% section 5: testing the correctness of the code
% section 6: related work and future work
% section 7: conclude in section 7
In chapter \ref{Testing} the testing methodology, chapter \ref{RelatedWork} lists the related and future work and finally the conclusion is in chapter \ref{Conclusions}.




